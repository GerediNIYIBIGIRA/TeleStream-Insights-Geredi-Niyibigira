name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.9'
  SPARK_VERSION: '3.5.0'
  DOCKER_REGISTRY: ghcr.io
  IMAGE_NAME: telestream-insights-hub

jobs:
  # ============================================
  # CODE QUALITY & LINTING
  # ============================================
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install flake8 black isort mypy bandit safety

      - name: Run Black (code formatting)
        run: black --check processing/ api/ tests/

      - name: Run isort (import sorting)
        run: isort --check-only processing/ api/ tests/

      - name: Run Flake8 (linting)
        run: flake8 processing/ api/ tests/ --max-line-length=120 --extend-ignore=E203,W503

      - name: Run MyPy (type checking)
        run: mypy processing/ api/ --ignore-missing-imports || true

      - name: Run Bandit (security)
        run: bandit -r processing/ api/ -ll

      - name: Check dependencies for vulnerabilities
        run: safety check --json

  # ============================================
  # UNIT TESTS
  # ============================================
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install Java (for PySpark)
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '11'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio pytest-xdist

      - name: Run unit tests
        run: |
          pytest tests/unit/ \
            -v \
            --cov=processing \
            --cov=api \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term \
            --junit-xml=test-results.xml \
            -n auto

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-${{ matrix.python-version }}

      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-${{ matrix.python-version }}
          path: |
            test-results.xml
            htmlcov/

  # ============================================
  # INTEGRATION TESTS
  # ============================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: telestream
          POSTGRES_PASSWORD: telestream123
          POSTGRES_DB: telestream_dw
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      kafka:
        image: confluentinc/cp-kafka:7.6.0
        ports:
          - 9092:9092
        env:
          KAFKA_BROKER_ID: 1
          KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
          KAFKA_PROCESS_ROLES: broker,controller
          KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
          KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '11'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio

      - name: Initialize database schema
        run: |
          PGPASSWORD=telestream123 psql -h localhost -U telestream -d telestream_dw -f tests/fixtures/schema.sql

      - name: Run integration tests
        env:
          DB_HOST: localhost
          DB_PORT: 5432
          DB_USER: telestream
          DB_PASSWORD: telestream123
          DB_NAME: telestream_dw
          REDIS_URL: redis://localhost:6379
          KAFKA_BROKERS: localhost:9092
        run: |
          pytest tests/integration/ \
            -v \
            -m integration \
            --junit-xml=integration-results.xml

      - name: Upload integration test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results
          path: integration-results.xml

  # ============================================
  # DATA QUALITY TESTS
  # ============================================
  data-quality-tests:
    name: Data Quality Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install great_expectations pandas pyspark

      - name: Validate data quality expectations
        run: |
          python -c "
          from great_expectations.data_context import DataContext
          context = DataContext('./great_expectations')
          results = context.run_checkpoint(checkpoint_name='test_checkpoint')
          assert results.success, 'Data quality checks failed'
          "

  # ============================================
  # SECURITY SCANNING
  # ============================================
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Run Snyk security scan
        uses: snyk/actions/python@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high

  # ============================================
  # BUILD DOCKER IMAGES
  # ============================================
  build-docker:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [code-quality, unit-tests]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.DOCKER_REGISTRY }}/${{ github.repository }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=sha

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            PYTHON_VERSION=${{ env.PYTHON_VERSION }}
            SPARK_VERSION=${{ env.SPARK_VERSION }}

      - name: Run Trivy on Docker image
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.meta.outputs.tags }}
          format: 'sarif'
          output: 'trivy-image-results.sarif'

  # ============================================
  # DEPLOY TO STAGING
  # ============================================
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [integration-tests, build-docker]
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    environment:
      name: staging
      url: https://staging.telestream.io
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --name telestream-staging --region us-east-1

      - name: Deploy with Helm
        run: |
          helm upgrade --install telestream ./infrastructure/kubernetes/helm/telestream \
            --namespace telestream-staging \
            --create-namespace \
            --values infrastructure/kubernetes/helm/values-staging.yaml \
            --set image.tag=${{ github.sha }} \
            --wait \
            --timeout 10m

      - name: Run smoke tests
        run: |
          kubectl run smoke-test \
            --namespace telestream-staging \
            --image=curlimages/curl:latest \
            --rm -it --restart=Never \
            -- curl -f http://telestream-api:8000/health

  # ============================================
  # DEPLOY TO PRODUCTION
  # ============================================
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment:
      name: production
      url: https://telestream.io
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --name telestream-prod --region us-east-1

      - name: Deploy with Helm (Blue-Green)
        run: |
          # Deploy green environment
          helm upgrade --install telestream-green ./infrastructure/kubernetes/helm/telestream \
            --namespace telestream-prod \
            --values infrastructure/kubernetes/helm/values-prod.yaml \
            --set image.tag=${{ github.sha }} \
            --set nameOverride=telestream-green \
            --wait \
            --timeout 15m

          # Run health checks
          kubectl wait --for=condition=ready pod \
            -l app=telestream-green \
            -n telestream-prod \
            --timeout=300s

          # Switch traffic to green
          kubectl patch service telestream-api \
            -n telestream-prod \
            --type merge \
            -p '{"spec":{"selector":{"app":"telestream-green"}}}'

          # Wait for traffic switch
          sleep 30

          # Remove old blue deployment
          helm uninstall telestream-blue -n telestream-prod || true

          # Rename green to blue for next deployment
          helm upgrade telestream-blue telestream-green \
            -n telestream-prod \
            --reuse-values

      - name: Run production smoke tests
        run: |
          curl -f https://telestream.io/health
          curl -f https://telestream.io/api/v1/metrics/realtime \
            -H "X-API-Key: ${{ secrets.PROD_API_KEY }}"

      - name: Notify deployment success
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Production deployment successful! :rocket:'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: success()

      - name: Rollback on failure
        if: failure()
        run: |
          kubectl patch service telestream-api \
            -n telestream-prod \
            --type merge \
            -p '{"spec":{"selector":{"app":"telestream-blue"}}}'
          
          helm uninstall telestream-green -n telestream-prod

      - name: Notify deployment failure
        uses: 8398a7/action-slack@v3
        with:
          status: 'failure'
          text: 'Production deployment failed! Rolling back... :warning:'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: failure()

  # ============================================
  # PERFORMANCE TESTS
  # ============================================
  performance-tests:
    name: Performance & Load Tests
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: github.ref == 'refs/heads/develop'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install locust pytest pytest-benchmark

      - name: Run API load tests
        run: |
          locust -f tests/performance/locustfile.py \
            --host https://staging.telestream.io \
            --users 100 \
            --spawn-rate 10 \
            --run-time 5m \
            --headless \
            --csv results/load_test

      - name: Run Spark performance tests
        run: |
          pytest tests/performance/test_spark_perf.py \
            -v \
            -m performance \
            --benchmark-only \
            --benchmark-json=results/benchmark.json

      - name: Upload performance results
        uses: actions/upload-artifact@v3
        with:
          name: performance-results
          path: results/

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('results/benchmark.json', 'utf8'));
            const comment = `## Performance Test Results\n\n${JSON.stringify(results, null, 2)}`;
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # ============================================
  # DOCUMENTATION
  # ============================================
  update-docs:
    name: Update Documentation
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install mkdocs mkdocs-material mkdocstrings

      - name: Build documentation
        run: |
          mkdocs build

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./site

  # ============================================
  # CLEANUP
  # ============================================
  cleanup:
    name: Cleanup Old Artifacts
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Delete old artifacts
        uses: c-hive/gha-remove-artifacts@v1
        with:
          age: '7 days'
          skip-recent: 5

      - name: Clean up old Docker images
        run: |
          # Delete untagged images older than 7 days
          echo "Cleanup would happen here in production"

  # ============================================
  # NOTIFICATION
  # ============================================
  notify:
    name: Send Notifications
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: always()
    steps:
      - name: Send Slack notification
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          fields: repo,message,commit,author,action,eventName,ref,workflow
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}

      - name: Send email notification
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: 'CI/CD Pipeline Status: ${{ job.status }}'
          to: data-team@telestream.com
          from: GitHub Actions
          body: |
            Pipeline execution completed with status: ${{ job.status }}
            
            Repository: ${{ github.repository }}
            Branch: ${{ github.ref }}
            Commit: ${{ github.sha }}
            Author: ${{ github.actor }}
            
            View details: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

# ============================================
# WORKFLOW SUMMARY
# ============================================
# This CI/CD pipeline includes:
# 1. Code quality checks (linting, formatting, type checking)
# 2. Security scanning (Trivy, Snyk, Bandit)
# 3. Unit tests with coverage reporting
# 4. Integration tests with real services
# 5. Data quality validation
# 6. Docker image building and scanning
# 7. Blue-green deployment to staging and production
# 8. Performance and load testing
# 9. Documentation updates
# 10. Notifications and cleanup